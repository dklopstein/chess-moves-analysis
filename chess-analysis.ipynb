{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3919,"sourceType":"datasetVersion","datasetId":2321}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\nfrom transformers import DataCollatorWithPadding\nfrom transformers.trainer_callback import EarlyStoppingCallback, TrainerCallback, TrainerState, TrainerControl\nfrom datasets import Dataset\nfrom sklearn.model_selection import train_test_split\n\nfrom tokenizers import (\n    decoders,\n    models,\n    normalizers,\n    pre_tokenizers,\n    processors,\n    trainers,\n    Tokenizer,\n)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-10T17:03:55.698611Z","iopub.execute_input":"2024-03-10T17:03:55.699371Z","iopub.status.idle":"2024-03-10T17:04:14.579285Z","shell.execute_reply.started":"2024-03-10T17:03:55.699340Z","shell.execute_reply":"2024-03-10T17:04:14.578221Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/chess/games.csv\n","output_type":"stream"},{"name":"stderr","text":"2024-03-10 17:04:06.043286: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-10 17:04:06.043385: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-10 17:04:06.182177: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/chess/games.csv')\ngames = data[['winner', 'turns', 'white_rating', 'black_rating', 'moves', 'opening_eco']]\ngames = games[games['winner']!='draw']","metadata":{"execution":{"iopub.status.busy":"2024-03-10T17:04:14.581119Z","iopub.execute_input":"2024-03-10T17:04:14.581822Z","iopub.status.idle":"2024-03-10T17:04:14.838351Z","shell.execute_reply.started":"2024-03-10T17:04:14.581792Z","shell.execute_reply":"2024-03-10T17:04:14.837291Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"id2label = {0: \"white\", 1: \"black\"}\nlabel2id = {\"white\": 0, \"black\": 1}\n\nmodel = AutoModelForSequenceClassification.from_pretrained('bert-base-cased', id2label=id2label, label2id=label2id)\ntokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\ntokenizer.pre_tokenizer = pre_tokenizers.WhitespaceSplit()","metadata":{"execution":{"iopub.status.busy":"2024-03-10T17:07:21.898208Z","iopub.execute_input":"2024-03-10T17:07:21.898567Z","iopub.status.idle":"2024-03-10T17:07:25.606135Z","shell.execute_reply.started":"2024-03-10T17:07:21.898537Z","shell.execute_reply":"2024-03-10T17:07:25.605323Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c039d12a1e454003a181fb648923f91c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea6fb7dc330242c09a6e8bc0fe704cd3"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b909e30063e54085ada70068f2686aad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e967843793844bcd9bc3d1a55f58b45b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87b5b25bb9044aa6b99e0e00dd8dac55"}},"metadata":{}}]},{"cell_type":"code","source":"def preprocess_moves(examples):\n    for i in range(len(examples)):\n        temp = examples[i].split(' ')\n        examples[i] = \" \".join(temp[:20])\n    return examples\n\ndef preprocess(example):\n    tokenized_example = tokenizer(example['moves'])\n    tokenized_example['label'] = label2id[example['winner']]\n    return tokenized_example","metadata":{"execution":{"iopub.status.busy":"2024-03-10T17:07:26.914395Z","iopub.execute_input":"2024-03-10T17:07:26.915319Z","iopub.status.idle":"2024-03-10T17:07:26.920934Z","shell.execute_reply.started":"2024-03-10T17:07:26.915283Z","shell.execute_reply":"2024-03-10T17:07:26.919773Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"games['moves'] = preprocess_moves(list(games['moves']))","metadata":{"execution":{"iopub.status.busy":"2024-03-10T17:07:28.154265Z","iopub.execute_input":"2024-03-10T17:07:28.155153Z","iopub.status.idle":"2024-03-10T17:07:28.250501Z","shell.execute_reply.started":"2024-03-10T17:07:28.155120Z","shell.execute_reply":"2024-03-10T17:07:28.249683Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(games['moves'], games['winner'], test_size=0.2, random_state=40)\ntrain = pd.concat([X_train, y_train], axis=1)\ntrain_ds = Dataset.from_pandas(train)\ntest = pd.concat([X_test, y_test], axis=1)\ntest_ds = Dataset.from_pandas(test)\ntokenized_train = train_ds.map(preprocess)\ntokenized_train = tokenized_train.remove_columns(['winner'])\ntokenized_valid = test_ds.map(preprocess)\ntokenized_valid = tokenized_valid.remove_columns(['winner'])","metadata":{"execution":{"iopub.status.busy":"2024-03-10T17:07:29.410221Z","iopub.execute_input":"2024-03-10T17:07:29.411098Z","iopub.status.idle":"2024-03-10T17:07:34.749002Z","shell.execute_reply.started":"2024-03-10T17:07:29.411062Z","shell.execute_reply":"2024-03-10T17:07:34.748249Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/15286 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0b51cc51f6f4f838dd8ea0f651b355b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3822 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85914c1835a3434691047d35ccd9a7a8"}},"metadata":{}}]},{"cell_type":"code","source":"import evaluate\n\naccuracy = evaluate.load(\"accuracy\")\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)\n    return accuracy.compute(predictions=predictions, references=labels)","metadata":{"execution":{"iopub.status.busy":"2024-03-06T21:46:57.206378Z","iopub.execute_input":"2024-03-06T21:46:57.206969Z","iopub.status.idle":"2024-03-06T21:46:58.309310Z","shell.execute_reply.started":"2024-03-06T21:46:57.206937Z","shell.execute_reply":"2024-03-06T21:46:58.308536Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"trained_model_dir_path = '/kaggle/working'\noutput_dir = trained_model_dir_path + 'tts'\nbest_model_dir = trained_model_dir_path + '/best'\n\n\n\ntraining_args = TrainingArguments(\n    output_dir=output_dir,\n    load_best_model_at_end=True,\n    save_total_limit=1,\n    evaluation_strategy='epoch',\n    save_strategy='epoch',\n    warmup_ratio=0.2,\n    learning_rate=1e-5,\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    num_train_epochs=8,\n    report_to='none',\n    weight_decay=0.03,\n    lr_scheduler_type='cosine'\n)\n\nmodel = AutoModelForSequenceClassification.from_pretrained('bert-base-cased', id2label=id2label, label2id=label2id)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    tokenizer=tokenizer,\n    train_dataset=tokenized_train,\n    eval_dataset=tokenized_valid,\n    callbacks=[EarlyStoppingCallback(early_stopping_patience=5)],\n    compute_metrics=compute_metrics\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-03-06T21:47:09.356127Z","iopub.execute_input":"2024-03-06T21:47:09.356490Z","iopub.status.idle":"2024-03-06T22:01:58.588674Z","shell.execute_reply.started":"2024-03-06T21:47:09.356461Z","shell.execute_reply":"2024-03-06T22:01:58.587777Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3824' max='3824' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3824/3824 14:47, Epoch 8/8]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.684974</td>\n      <td>0.546049</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.695800</td>\n      <td>0.677539</td>\n      <td>0.565149</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.688000</td>\n      <td>0.665754</td>\n      <td>0.566719</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.672400</td>\n      <td>0.656042</td>\n      <td>0.583203</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.660900</td>\n      <td>0.657224</td>\n      <td>0.592098</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.644900</td>\n      <td>0.670932</td>\n      <td>0.590267</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.627100</td>\n      <td>0.682490</td>\n      <td>0.596808</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.613300</td>\n      <td>0.685620</td>\n      <td>0.597070</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Checkpoint destination directory /kaggle/workingtts/checkpoint-2868 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n","output_type":"stream"},{"execution_count":66,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=3824, training_loss=0.6537001182843452, metrics={'train_runtime': 887.6866, 'train_samples_per_second': 137.76, 'train_steps_per_second': 4.308, 'total_flos': 4049289419766000.0, 'train_loss': 0.6537001182843452, 'epoch': 8.0})"},"metadata":{}}]},{"cell_type":"code","source":"import scipy\n","metadata":{"execution":{"iopub.status.busy":"2024-03-10T17:04:56.778605Z","iopub.execute_input":"2024-03-10T17:04:56.779514Z","iopub.status.idle":"2024-03-10T17:04:56.786731Z","shell.execute_reply.started":"2024-03-10T17:04:56.779473Z","shell.execute_reply":"2024-03-10T17:04:56.785714Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":".597070 * 3822","metadata":{"execution":{"iopub.status.busy":"2024-03-10T17:08:40.298530Z","iopub.execute_input":"2024-03-10T17:08:40.299166Z","iopub.status.idle":"2024-03-10T17:08:40.305005Z","shell.execute_reply.started":"2024-03-10T17:08:40.299131Z","shell.execute_reply":"2024-03-10T17:08:40.304073Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"2282.0015399999997"},"metadata":{}}]},{"cell_type":"code","source":"1-scipy.stats.binom.cdf(k=2282, n=3822, p=0.5)","metadata":{"execution":{"iopub.status.busy":"2024-03-10T17:10:01.810669Z","iopub.execute_input":"2024-03-10T17:10:01.811505Z","iopub.status.idle":"2024-03-10T17:10:01.818156Z","shell.execute_reply.started":"2024-03-10T17:10:01.811471Z","shell.execute_reply":"2024-03-10T17:10:01.817229Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"0.0"},"metadata":{}}]},{"cell_type":"markdown","source":"","metadata":{}}]}